---
Biography
---
I am is a final year Ph.D student at the University of Sydney. Yuxin Xue received Electrical Engineering degree in Electronic Science and Technology (Optoelectronics) in 2019 from Tianjin University, Tianjin, China. She is currently working towards the Ph.D degree in computer science in the University of Sydney, Sydney, Australia. 

My research interests include medical image analysis, multi-modal learning (MML), and large foundation models (LFM), with a focus on enhancing medical imaging through advanced deep learning techniques and integrating multi-modal data for improved diagnostic accuracy. 

I will join the Biomedical Data Analysis and Visualization (BDAV) group at the School of Computer Science, The University of Sydney, as a Postdoctoral Researcher under the supervision of Prof. Jinman Kim.



Publications
======
Like many other Jekyll-based GitHub Pages templates, Academic Pages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Publication
======
Y. Xue, L. Bi, Y. Peng, M. Fulham, D. D. Feng and J. Kim, ’PET Synthesis via Self-Supervised Adaptive Residual Estimation Generative Adversarial Net- work,’ IEEE Transactions on Radiation and Plasma Medical Sciences, vol. 8, no. 4, pp. 426-438, April 2024.

M. Meng, *Y. Xue, M. Fulham, D. D. Feng and J. Kim, ’Capturing Finer- grained Long-range Dependency at Higher Resolution: An Empirical Invest- igation of MLPs in Medical Image Dense Prediction,’ IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024, (Under review).

Y. Xue, Y. Peng, L. Bi, D. Feng and J. Kim, ’CG-3DSRGAN: A classifica- tion guided 3D generative adversarial network for image quality recovery from low-dose PET images,’ 2023 45th Annual International Conference of the IEEE Engineering in Medicine Biology Society (EMBC), Sydney, Australia, 2023, pp. 1-4.

B. Tan, Y. Xue, L. Bi and J. Kim, ’Full-TrSUN: A Full-Resolution Transformer UNet for high quality PET image synthesis,’ International Workshop on Ma- chine Learning in Medical Imaging, 2024, Accepted.

B. Tan, Y. Xue, L. Bi and J. Kim, ’A Reverse Method of Data Augmentation for High Quality PET Image Synthesis,’ 2024 International Conference on Digital Image Computing: Techniques and Applications (DICTA), 2024, Accepted.

Y. Xue, X. Qiao, H. Wang, D. D. Feng, Q. Huang, L. Biao, and J. Kim, ’Ultra- low Dose PET synthesis from Sequential Total-body PET/CT using Time-point transformation,’

Y. Xue, M. Meng, M. Fulham and J. Kim, ’Hybrid-CMLP: Hybrid CNN-MLP Networks for PET Synthesis from Low-Dose PET Images,'

X. Qiao, Y. Xue, H. Wang, D. D. Feng, J. Kim, L. Biao, and Q. Huang, ’Low- Dose 68Ga-FAPI PET Enhancement with Multi-Modality MRI Priors,’ 


